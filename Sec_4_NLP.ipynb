{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "679640d8",
      "metadata": {
        "id": "679640d8"
      },
      "source": [
        "# Tokenize"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6781400c",
      "metadata": {
        "id": "6781400c",
        "outputId": "24af08bb-9cea-4008-e4b2-6a14c10a462a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "showing info https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/index.xml\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3583e2e3",
      "metadata": {
        "id": "3583e2e3",
        "outputId": "ab1b7e35-3360-4de4-a2f4-d58beab47496"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['``',\n",
              " 'Nikola',\n",
              " 'Tesla',\n",
              " 'was',\n",
              " 'a',\n",
              " 'Serbian-American',\n",
              " 'inventor',\n",
              " ',',\n",
              " 'electrical',\n",
              " 'engineer',\n",
              " ',',\n",
              " 'mechanical',\n",
              " 'engineer',\n",
              " ',',\n",
              " 'and',\n",
              " 'futurist',\n",
              " 'best',\n",
              " 'known',\n",
              " 'for',\n",
              " 'his',\n",
              " 'contributions',\n",
              " 'to',\n",
              " 'the',\n",
              " 'design',\n",
              " 'of',\n",
              " 'the',\n",
              " 'modern',\n",
              " 'alternating',\n",
              " 'current',\n",
              " 'electricity',\n",
              " 'supply',\n",
              " 'system',\n",
              " '.']"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from nltk.tokenize import sent_tokenize, word_tokenize \n",
        "example_string = \"\"\"\" \n",
        "Nikola Tesla was a Serbian-American inventor, electrical engineer, mechanical engineer, and futurist best known for his contributions to the design of the modern alternating current electricity supply system.\n",
        "\"\"\" \n",
        "word_tokenize (example_string)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "57727eb6",
      "metadata": {
        "id": "57727eb6",
        "outputId": "0f7589b7-7be0-48af-cb8b-2276310c18aa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['How are you, Shrouk']\n"
          ]
        }
      ],
      "source": [
        "from nltk.tokenize import sent_tokenize\n",
        "mytext =\"How are you, Shrouk\"\n",
        "print (sent_tokenize(mytext))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "20414051",
      "metadata": {
        "id": "20414051",
        "outputId": "5fda33e4-fbe9-4638-e6ce-4de8774f7f16"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['How', 'are', 'you', ',', 'Shrouk']\n"
          ]
        }
      ],
      "source": [
        "from nltk.tokenize import word_tokenize\n",
        "mytext =\"How are you, Shrouk\"\n",
        "print (word_tokenize(mytext))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0227b1de",
      "metadata": {
        "id": "0227b1de"
      },
      "source": [
        "# Wordnet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3fb4ee28",
      "metadata": {
        "id": "3fb4ee28",
        "outputId": "8ce8f83d-2690-4597-c3c1-e8ea09b2e60c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "a written work or composition that has been published (printed on pages bound together)\n"
          ]
        }
      ],
      "source": [
        "from nltk.corpus import wordnet\n",
        "syn = wordnet.synsets(\"book\")\n",
        "print(syn[0].definition())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f86879df",
      "metadata": {
        "id": "f86879df",
        "outputId": "61135d83-2c57-4a72-e06b-91cee4a1d091"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['network', 'web', 'network', 'net', 'network', 'mesh', 'meshing', 'meshwork', 'network', 'network', 'electronic_network', 'network']\n"
          ]
        }
      ],
      "source": [
        "from nltk.corpus import wordnet\n",
        "synonyms = []\n",
        "for syn in wordnet.synsets('network'):\n",
        "    for lemma in syn.lemmas():\n",
        "        synonyms.append(lemma.name())\n",
        "print(synonyms)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d974fef1",
      "metadata": {
        "id": "d974fef1"
      },
      "source": [
        "# Stemmer "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "40d7622c",
      "metadata": {
        "id": "40d7622c",
        "outputId": "c75bd6ee-26b9-4a21-cf66-112c16c90848"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "programs : program\n",
            "nerworks : nerwork\n",
            "programming : program\n"
          ]
        }
      ],
      "source": [
        "from nltk.stem import PorterStemmer\n",
        "from nltk.tokenize import word_tokenize\n",
        "ps = PorterStemmer()\n",
        "words = [\"programs\", \"nerworks\", \"programming\" ]\n",
        "for w in words:\n",
        "    print(w, \":\", ps.stem(w))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3e3bd414",
      "metadata": {
        "id": "3e3bd414",
        "outputId": "d55d98f8-3ac2-43d2-85bd-e4203d5ec35a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "`` : ``\n",
            "Nikola : nikola\n",
            "Tesla : tesla\n",
            "was : wa\n",
            "a : a\n",
            "Serbian-American : serbian-american\n",
            "inventor : inventor\n",
            ", : ,\n",
            "electrical : electr\n",
            "engineer : engin\n",
            ", : ,\n",
            "mechanical : mechan\n",
            "engineer : engin\n",
            ", : ,\n",
            "and : and\n",
            "futurist : futurist\n",
            "best : best\n",
            "known : known\n",
            "for : for\n",
            "his : hi\n",
            "contributions : contribut\n",
            "to : to\n",
            "the : the\n",
            "design : design\n",
            "of : of\n",
            "the : the\n",
            "modern : modern\n",
            "alternating : altern\n",
            "current : current\n",
            "electricity : electr\n",
            "supply : suppli\n",
            "system : system\n",
            ". : .\n"
          ]
        }
      ],
      "source": [
        "from nltk.stem import PorterStemmer\n",
        "from nltk.tokenize import word_tokenize\n",
        "ps = PorterStemmer()\n",
        "sentence =  \"\"\"\"\n",
        "Nikola Tesla was a Serbian-American inventor, electrical engineer, mechanical engineer, and futurist best known for his contributions to the design of the modern alternating current electricity supply system.\n",
        "\"\"\"\n",
        "words = word_tokenize(sentence)\n",
        "\n",
        "for w in words:\n",
        "    print(w, \":\", ps.stem(w))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ce631599",
      "metadata": {
        "id": "ce631599"
      },
      "source": [
        "# Stopwords"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e53a2566",
      "metadata": {
        "id": "e53a2566",
        "outputId": "33e9f63a-f98e-48b5-acc6-aa21afd8c472"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['work', 'play', 'makes', 'jack', 'dull', 'boy', '.']\n"
          ]
        }
      ],
      "source": [
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import sent_tokenize, word_tokenize\n",
        "data = \" work and not play makes jack dull boy.\"\n",
        "stopwords= set(stopwords.words('English'))\n",
        "words= word_tokenize(data)\n",
        "wordsFilter=[]\n",
        "\n",
        "for w in words:\n",
        "    if w not in stopwords:\n",
        "        wordsFilter.append(w)\n",
        "print (wordsFilter)        \n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "882c38ca",
      "metadata": {
        "id": "882c38ca"
      },
      "source": [
        "# Lemmatizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "11591b1c",
      "metadata": {
        "id": "11591b1c",
        "outputId": "bf936f55-58fb-446e-9b3f-7e4f830806f9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "swim\n",
            "swimming\n",
            "swimming\n",
            "swimming\n"
          ]
        }
      ],
      "source": [
        "from nltk.stem import WordNetLemmatizer\n",
        "lemmatizer =  WordNetLemmatizer() \n",
        "print (lemmatizer.lemmatize('swimming', pos = 'v'))\n",
        "print (lemmatizer.lemmatize('swimming', pos = 'n'))\n",
        "print (lemmatizer.lemmatize('swimming', pos = 'a'))\n",
        "print (lemmatizer.lemmatize('swimming', pos = 'r'))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3f79b1ff",
      "metadata": {
        "id": "3f79b1ff"
      },
      "source": [
        "# Lemmatizer & stemmer "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5b231337",
      "metadata": {
        "id": "5b231337",
        "outputId": "3d2a214f-aada-4733-9a15-4cc83ba19d2a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "stone\n",
            "joke\n",
            "lisa\n",
            "speak\n",
            "....................\n",
            "stone\n",
            "joke\n",
            "lisa\n",
            "speaking\n"
          ]
        }
      ],
      "source": [
        "from nltk.stem import PorterStemmer\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "lemmatizer =  WordNetLemmatizer() \n",
        "ps = PorterStemmer()\n",
        "\n",
        "print(ps.stem(\"stones\"))\n",
        "print(ps.stem(\"jokes\"))\n",
        "print(ps.stem(\"lisa\"))\n",
        "print(ps.stem(\"speaking\"))\n",
        "print('....................')\n",
        "print (lemmatizer.lemmatize('stones'))\n",
        "print (lemmatizer.lemmatize('jokes'))\n",
        "print (lemmatizer.lemmatize('lisa'))\n",
        "print (lemmatizer.lemmatize('speaking'))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "69deae9b",
      "metadata": {
        "id": "69deae9b"
      },
      "source": [
        "# Part of Speech (POS)_TAG"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7cab81c7",
      "metadata": {
        "id": "7cab81c7",
        "outputId": "ecdd5e2c-0003-4b62-cf20-f2739f0f354d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[('They', 'PRP'), ('refuse', 'VBP'), ('to', 'TO'), ('permit', 'VB'), ('us', 'PRP'), ('to', 'TO'), ('obtain', 'VB'), ('the', 'DT'), ('refuse', 'NN'), ('permit', 'NN')]\n"
          ]
        }
      ],
      "source": [
        "from nltk.tokenize import word_tokenize \n",
        "from nltk import pos_tag\n",
        "text = word_tokenize('They refuse to permit us to obtain the refuse permit')\n",
        "print(pos_tag(text))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9be895f0",
      "metadata": {
        "id": "9be895f0"
      },
      "source": [
        "# Tokenize (Spacy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "dfd0423e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dfd0423e",
        "outputId": "d9f559e2-2da5-43c8-8adf-1e11924d9b9d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "you\n",
            "only\n",
            "live\n",
            "once\n",
            ",\n",
            "but\n",
            "if\n",
            "you\n",
            "do\n",
            "it\n",
            "right\n",
            ",\n",
            "once\n",
            "is\n",
            "enough\n",
            ".\n"
          ]
        }
      ],
      "source": [
        "import spacy\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "doc= nlp(\"you only live once, but if you do it right, once is enough.\")\n",
        "for token in doc:\n",
        "    print(token.text)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f9a4a34e",
      "metadata": {
        "id": "f9a4a34e"
      },
      "source": [
        "# Sentence segmentation "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "c4b09bec",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c4b09bec",
        "outputId": "c2275028-3652-462a-efe2-683ce9906c8f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Nikola Tesla was a Serbian-American inventor, electrical engineer, mechanical engineer, and futurist best known for his contributions to the design of the modern alternating current electricity supply system.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import spacy \n",
        "\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "doc = nlp(u\"\"\"\n",
        "Nikola Tesla was a Serbian-American inventor, electrical engineer, mechanical engineer, and futurist best known for his contributions to the design of the modern alternating current electricity supply system.\n",
        "\"\"\")\n",
        "for sent in doc.sents:\n",
        "    print(sent)\n",
        "          "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "523b9304",
      "metadata": {
        "id": "523b9304"
      },
      "source": [
        "# Named Entity Recognition (NER)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "fa8b8e9d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fa8b8e9d",
        "outputId": "6af281ef-bce2-43a4-deef-a1797ca707ba"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Serbian 20 27 NORP\n"
          ]
        }
      ],
      "source": [
        "import spacy \n",
        "\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "sentence = \"\"\"\n",
        "Nikola Tesla was a Serbian-American inventor, electrical engineer, mechanical engineer, and futurist best known for his contributions to the design of the modern alternating current electricity supply system.\n",
        "\"\"\"\n",
        "doc =nlp(sentence)\n",
        "for ent in doc.ents:\n",
        "    print(ent.text, ent.start_char, ent.end_char, ent.label_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9e37cc9a",
      "metadata": {
        "id": "9e37cc9a"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}